{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d66086",
   "metadata": {},
   "source": [
    "# Parte 1: Extracción de datos a través de Web Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa80885",
   "metadata": {},
   "source": [
    "## Importar las librerias con las que trabajaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79479f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b92839",
   "metadata": {},
   "source": [
    "## Extraer la fecha actual para la recopilación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec0c7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-19 19:41:22.400037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hoy = datetime.today()\n",
    "fecha_inicio = hoy - timedelta(days=7)\n",
    "todos_sismos = []\n",
    "print(hoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea754e2",
   "metadata": {},
   "source": [
    "- Con esto podemos saber la fecha actual y lo mas importante, el dia en el que estamos, este dato lo utilizaremos para poder extraer los datos de cada dia que queramos de la página web a la que haremos web scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e1b0c",
   "metadata": {},
   "source": [
    "## Creación de estructura repetitiva para la extracción de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fd6be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrayendo: https://www.sismologia.cl/sismicidad/catalogo/2025/10/20251019.html\n",
      "Extrayendo: https://www.sismologia.cl/sismicidad/catalogo/2025/10/20251018.html\n",
      "Extrayendo: https://www.sismologia.cl/sismicidad/catalogo/2025/10/20251017.html\n",
      "Extrayendo: https://www.sismologia.cl/sismicidad/catalogo/2025/10/20251016.html\n",
      "Extrayendo: https://www.sismologia.cl/sismicidad/catalogo/2025/10/20251015.html\n",
      "Extrayendo: https://www.sismologia.cl/sismicidad/catalogo/2025/10/20251014.html\n",
      "Extrayendo: https://www.sismologia.cl/sismicidad/catalogo/2025/10/20251013.html\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):  # Recorre los últimos dias i, si queremos extraer más días, cambiar el rango, 7 para tener datos rapidamente\n",
    "    fecha = hoy - timedelta(days=i)\n",
    "    url = f\"https://www.sismologia.cl/sismicidad/catalogo/{fecha.year}/{fecha.month:02d}/{fecha.strftime('%Y%m%d')}.html\"\n",
    "    print(f\"Extrayendo: {url}\")\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"No se pudo acceder a {url}\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    tabla = soup.find(\"table\", class_=\"sismologia detalle\")\n",
    "    if not tabla:\n",
    "        print(f\"No se encontró tabla para {fecha}\")\n",
    "        continue\n",
    "\n",
    "    filas = tabla.find_all(\"tr\")[1:] \n",
    "\n",
    "    for fila in filas:\n",
    "        celdas = fila.find_all(\"td\")\n",
    "        if len(celdas) < 5:\n",
    "            continue\n",
    "\n",
    "        fecha_local = celdas[0].get_text(strip=True)\n",
    "        fecha_utc = celdas[1].get_text(strip=True)\n",
    "        lat_long_raw = celdas[2].get_text(strip=True)\n",
    "        lat_long = [x for x in lat_long_raw.replace('\\n', ' ').split(' ') if x]\n",
    "        latitud = lat_long[0] if len(lat_long) > 0 else \"\"\n",
    "        longitud = lat_long[1] if len(lat_long) > 1 else \"\"\n",
    "        profundidad = celdas[3].get_text(strip=True)\n",
    "        magnitud = celdas[4].get_text(strip=True)\n",
    "\n",
    "        todos_sismos.append({\n",
    "            \"fecha_local\": fecha_local,\n",
    "            \"fecha_utc\": fecha_utc,\n",
    "            \"latitud\": latitud,\n",
    "            \"longitud\": longitud,\n",
    "            \"profundidad\": profundidad,\n",
    "            \"magnitud\": magnitud\n",
    "        })\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada284a",
   "metadata": {},
   "source": [
    "- De esta extracción obtenemos los siguientes datos. \n",
    "1. La fecha local del sismo.\n",
    "2. El tiempo universal coordinado o UTC\n",
    "3. La latitud del sismo\n",
    "4. La longitud del sismo\n",
    "5. La profundidad del sismo\n",
    "6. La magnitud de este.\n",
    "- Con estos datos podemos obtener mucha información respecto a los sismos en Chile, podemos clasificar las regiones por sismos, la cantidad de estos, la potencia (leve, moderada, grave), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b85dbb3",
   "metadata": {},
   "source": [
    "## Guardar los datos en almacenados en un CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4f1f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: sismos.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_sismos = pd.DataFrame(todos_sismos)\n",
    "df_sismos.to_csv(\"sismos.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"Guardado en: sismos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72753b",
   "metadata": {},
   "source": [
    "- Con esto guardamos toda la información en un CSV, sin embargo al guardar de forma directa se generan errores, por lo que en la siguiente sección nos encargaremos de la correción y limpieza se errores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3d303",
   "metadata": {},
   "source": [
    "# Parte 2: Correción de errores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f73ffa6",
   "metadata": {},
   "source": [
    "## Leer el csv con pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0404df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         fecha_local            fecha_utc  \\\n",
      "0          2025-10-19 18:52:5961 km al SE de Socaire  2025-10-19 21:52:59   \n",
      "1         2025-10-19 16:35:5139 km al SO de OllagÃ¼e  2025-10-19 19:35:51   \n",
      "2  2025-10-19 15:50:3741 km al O de San Pedro de ...  2025-10-19 18:50:37   \n",
      "3            2025-10-19 14:22:5546 km al N de Calama  2025-10-19 17:22:55   \n",
      "4          2025-10-19 14:06:3424 km al O de OllagÃ¼e  2025-10-19 17:06:34   \n",
      "\n",
      "          latitud  longitud profundidad magnitud  \n",
      "0  -24.038-67.550       NaN      245 km   2.9 Ml  \n",
      "1  -21.540-68.423       NaN      129 km   3.1 Ml  \n",
      "2  -22.832-68.587       NaN      113 km   2.7 Ml  \n",
      "3  -22.084-68.783       NaN      100 km   3.1 Ml  \n",
      "4  -21.196-68.479       NaN      133 km   2.7 Ml  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sismos.csv\", encoding=\"utf-8\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fecda",
   "metadata": {},
   "source": [
    "- Con esta información nos damos cuenta de que la latitud y la longitud se almacenan en la misma variable, debido a que no se separan en la página web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abafffb1",
   "metadata": {},
   "source": [
    "## Arreglar latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f75037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         fecha_local            fecha_utc  \\\n",
      "0          2025-10-19 18:52:5961 km al SE de Socaire  2025-10-19 21:52:59   \n",
      "1         2025-10-19 16:35:5139 km al SO de OllagÃ¼e  2025-10-19 19:35:51   \n",
      "2  2025-10-19 15:50:3741 km al O de San Pedro de ...  2025-10-19 18:50:37   \n",
      "3            2025-10-19 14:22:5546 km al N de Calama  2025-10-19 17:22:55   \n",
      "4          2025-10-19 14:06:3424 km al O de OllagÃ¼e  2025-10-19 17:06:34   \n",
      "\n",
      "   latitud longitud profundidad magnitud  \n",
      "0  -24.038  -67.550      245 km   2.9 Ml  \n",
      "1  -21.540  -68.423      129 km   3.1 Ml  \n",
      "2  -22.832  -68.587      113 km   2.7 Ml  \n",
      "3  -22.084  -68.783      100 km   3.1 Ml  \n",
      "4  -21.196  -68.479      133 km   2.7 Ml  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcx\\AppData\\Local\\Temp\\ipykernel_244\\3256924476.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-67.550' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i, \"longitud\"] = \"-\" + partes[1]\n"
     ]
    }
   ],
   "source": [
    "for i, fila in df.iterrows():\n",
    "    if pd.isna(fila[\"longitud\"]) or str(fila[\"longitud\"]).strip() == \"\":\n",
    "        latlong = str(fila[\"latitud\"]).strip()\n",
    "        if \"-\" in latlong[1:]:  # evitar el primer signo negativo\n",
    "            partes = latlong[1:].split(\"-\", 1)\n",
    "            if len(partes) == 2:\n",
    "                df.at[i, \"latitud\"] = latlong[0] + partes[0]\n",
    "                df.at[i, \"longitud\"] = \"-\" + partes[1]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceedb5d",
   "metadata": {},
   "source": [
    "- Con esta correción podemos separar las latitudes y longitudes, solo falta guardarlos, en este caso, en un nuevo CSV llamado BDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a309a",
   "metadata": {},
   "source": [
    "## Guardar datos en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec60fc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo corregido guardado como: bdd.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"bdd.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Archivo corregido guardado como: bdd.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fd08b",
   "metadata": {},
   "source": [
    "- Ahora podremos tener todos los datos guardados correctamente y sin fallos, pero se nos presenta un nuevo problema, si nos fijamos en la magnitud, esta no es un numero, si no que un numero mas el tipo de dato (Ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100bfea",
   "metadata": {},
   "source": [
    "## Convertir magnitudes a decimales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e837b2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.9\n",
      "1    3.1\n",
      "2    2.7\n",
      "3    3.1\n",
      "4    2.7\n",
      "Name: magnitud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['magnitud'] = (\n",
    "    df['magnitud']\n",
    "    .astype(str)\n",
    "    .str.extract(r'([\\d,.]+)')\n",
    "    .replace(',', '.', regex=True)\n",
    "    .astype(float)\n",
    ")\n",
    "print(df['magnitud'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb27ba",
   "metadata": {},
   "source": [
    "- Con esto tenemos todas las magnitudes transformadas a float como se indica en dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ba4d0",
   "metadata": {},
   "source": [
    "## Solucionar problemas de tipo de dato con longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f084b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitud     float64\n",
      "longitud    float64\n",
      "dtype: object\n",
      "   latitud  longitud\n",
      "0  -24.038   -67.550\n",
      "1  -21.540   -68.423\n",
      "2  -22.832   -68.587\n",
      "3  -22.084   -68.783\n",
      "4  -21.196   -68.479\n"
     ]
    }
   ],
   "source": [
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for i, fila in df.iterrows():\n",
    "    lat_s = str(fila[\"latitud\"]) if not pd.isna(fila[\"latitud\"]) else \"\"\n",
    "    lon_s = str(fila[\"longitud\"]) if not pd.isna(fila[\"longitud\"]) else \"\"\n",
    "\n",
    "    if lon_s.strip() == \"\" or lon_s.lower() in (\"nan\", \"none\"):\n",
    "        nums = re.findall(r'-?\\d+(?:\\.\\d+)?', lat_s)\n",
    "        if len(nums) >= 2:\n",
    "            latitudes.append(nums[0])\n",
    "            longitudes.append(nums[1])\n",
    "            continue\n",
    "\n",
    "    lat_num = re.search(r'-?\\d+(?:\\.\\d+)?', lat_s)\n",
    "    lon_num = re.search(r'-?\\d+(?:\\.\\d+)?', lon_s)\n",
    "    latitudes.append(lat_num.group(0) if lat_num else None)\n",
    "    longitudes.append(lon_num.group(0) if lon_num else None)\n",
    "\n",
    "df[\"latitud\"] = pd.to_numeric(latitudes, errors=\"coerce\")\n",
    "df[\"longitud\"] = pd.to_numeric(longitudes, errors=\"coerce\")\n",
    "\n",
    "print(df[[\"latitud\", \"longitud\"]].dtypes)\n",
    "print(df[[\"latitud\", \"longitud\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df520006",
   "metadata": {},
   "source": [
    "- Con esto nos facilitamos el manejo de estos datos, para la siguiente parte, que es usar los datos para tener información útil que podamos mostrar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85e6f3",
   "metadata": {},
   "source": [
    "# Parte 3: Creación de nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f226f8",
   "metadata": {},
   "source": [
    "- Con los datos obtenidos, podemos crear información nueva que nos sirva para el análisis de datos, en este caso, crearemos tres nuevas columnas región para indicar la región en la que se produjo el sismo (de forma aproximada), enlace a google maps (para que al hacer click, dirija instanteneamente al punto exacto donde se produjo el sismo) y rango profundidad (para la manipulación de datos mas intuitiva y entendible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b7481",
   "metadata": {},
   "source": [
    "## Ubicar aproximadamente los sismos en una región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88e2edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Antofagasta\n",
      "1    Antofagasta\n",
      "2    Antofagasta\n",
      "3    Antofagasta\n",
      "4       Tarapacá\n",
      "Name: region, dtype: object\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "# Rangos de latitud para cada región (al chile ser un país largo en latitud, podemos usar esto para asignar regiones aproximadas)\n",
    "rangos_regiones = [\n",
    "    (-19.000, -17.300, \"Arica y Parinacota\"),\n",
    "    (-21.300, -19.000, \"Tarapacá\"),\n",
    "    (-25.300, -21.300, \"Antofagasta\"),\n",
    "    (-29.300, -25.300, \"Atacama\"),\n",
    "    (-32.000, -29.300, \"Coquimbo\"),\n",
    "    (-32.950, -32.000, \"Valparaíso\"),\n",
    "    (-34.150, -32.950, \"Región Metropolitana de Santiago\"),\n",
    "    (-35.000, -34.150, \"Libertador B. O'Higgins\"),\n",
    "    (-36.250, -35.000, \"Maule\"),\n",
    "    (-36.850, -36.250, \"Ñuble\"),\n",
    "    (-37.900, -36.850, \"Biobío\"),\n",
    "    (-40.500, -37.900, \"La Araucanía\"),\n",
    "    (-40.580, -39.500, \"Los Ríos\"),\n",
    "    (-43.600, -40.580, \"Los Lagos\"),\n",
    "    (-48.000, -43.600, \"Aysén del General Carlos Ibáñez del Campo\"),\n",
    "    (-52.810, -48.000, \"Magallanes y de la Antártica Chilena\")\n",
    "]\n",
    "# Guardar las regiones en una variable\n",
    "regiones = []\n",
    "\n",
    "for lat in df[\"latitud\"]:\n",
    "    region_encontrada = \"Fuera de Chile\"\n",
    "    for lat_min, lat_max, region in rangos_regiones:\n",
    "        if lat_min <= lat <= lat_max:\n",
    "            region_encontrada = region\n",
    "            break\n",
    "    regiones.append(region_encontrada)\n",
    "\n",
    "df[\"region\"] = regiones\n",
    "print(df[\"region\"].head())\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18d596",
   "metadata": {},
   "source": [
    "- Con esto ya tenemos asignadas regiones a cada uno de los sismos, pero el centro sismológico nacional también detecta sismos afuera de Chile, por lo que nos desharemos de estos datos que no nos sirven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80109c9b",
   "metadata": {},
   "source": [
    "## Limpieza de regiones Fuera de Chile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adbaf129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     latitud  longitud              region\n",
      "0    -24.038   -67.550         Antofagasta\n",
      "1    -21.540   -68.423         Antofagasta\n",
      "2    -22.832   -68.587         Antofagasta\n",
      "3    -22.084   -68.783         Antofagasta\n",
      "4    -21.196   -68.479            Tarapacá\n",
      "..       ...       ...                 ...\n",
      "163  -30.698   -71.666            Coquimbo\n",
      "164  -30.680   -71.768            Coquimbo\n",
      "165  -30.673   -71.668            Coquimbo\n",
      "166  -40.811   -75.538           Los Lagos\n",
      "167  -18.908   -69.257  Arica y Parinacota\n",
      "\n",
      "[166 rows x 3 columns]\n",
      "Datos fuera de Chile eliminados. Total registros: 166\n"
     ]
    }
   ],
   "source": [
    "df = df[df['region'] != \"Fuera de Chile\"]\n",
    "print(df[['latitud', 'longitud', 'region']])\n",
    "print(f\"Datos fuera de Chile eliminados. Total registros: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92496c5",
   "metadata": {},
   "source": [
    "## Creación de enlaces para la visualización en google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffb9b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitud  longitud                                      maps_link\n",
      "0  -24.038   -67.550   https://www.google.com/maps?q=-24.038,-67.55\n",
      "1  -21.540   -68.423   https://www.google.com/maps?q=-21.54,-68.423\n",
      "2  -22.832   -68.587  https://www.google.com/maps?q=-22.832,-68.587\n",
      "3  -22.084   -68.783  https://www.google.com/maps?q=-22.084,-68.783\n",
      "4  -21.196   -68.479  https://www.google.com/maps?q=-21.196,-68.479\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    lat = row[\"latitud\"]\n",
    "    lon = row[\"longitud\"]\n",
    "    link = f\"https://www.google.com/maps?q={lat},{lon}\"\n",
    "    links.append(link)\n",
    "\n",
    "df[\"maps_link\"] = links\n",
    "print(df[[\"latitud\", \"longitud\", \"maps_link\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9721c9e",
   "metadata": {},
   "source": [
    "- Ahora al hacer click sobre un enlace cualquiera, tendremos las coordenadas exactas del evento, información útil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa5642",
   "metadata": {},
   "source": [
    "## Limpieza de profundidad y creación de rangos de profundidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb4001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   profundidad rango_profundidad\n",
      "0        245.0        200–500 km\n",
      "1        129.0        100–200 km\n",
      "2        113.0        100–200 km\n",
      "3        100.0         60–100 km\n",
      "4        133.0        100–200 km\n"
     ]
    }
   ],
   "source": [
    "df['profundidad'] = (df['profundidad'].astype(str).str.extract(r'([\\d.]+)').astype(float))\n",
    "\n",
    "bins = [0, 10, 30, 60, 100, 200, 500, np.inf]\n",
    "labels_profundidad = ['<10 km', '10–30 km', '30–60 km', '60–100 km', '100–200 km', '200–500 km', '>500 km']\n",
    "df['rango_profundidad'] = pd.cut(df['profundidad'], bins=bins, labels=labels)\n",
    "print(df[['profundidad', 'rango_profundidad']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03868874",
   "metadata": {},
   "source": [
    "- En este caso tuvimos que transformar el tipo de dato de profundidad a un float y luego establecer profundidades para tener de rango, esto es útil ya que nos sirve para mostrar información de los sismos de forma mas clara en los gráficos, ya que mostrar muchas columnas, cada una representando una profundidad diferente solo la hara dificil de entender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140aff6b",
   "metadata": {},
   "source": [
    "## Categorizar magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff11cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-np.inf, 3.5, 5.0, np.inf]\n",
    "labels = ['Leve', 'Moderado', 'Fuerte']\n",
    "df['categoria'] = pd.cut(df['magnitud'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de02e2",
   "metadata": {},
   "source": [
    "- Como en el caso de la profundidad es util guardar las magnitudes en intervalos para la facil representación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713532a8",
   "metadata": {},
   "source": [
    "## Guardar todo lo trabajado en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf51d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bdd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7ea39",
   "metadata": {},
   "source": [
    "- Con toda la información guardada, ya podemos empezar a trabajar con los datos y convertirlos en información útil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01de2c8",
   "metadata": {},
   "source": [
    "# Parte 4: Transformación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c91bb",
   "metadata": {},
   "source": [
    "## Conteo de datos por columnas (categoria, region, magnitud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88433562",
   "metadata": {},
   "source": [
    "### Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a0a361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteos totales por categoría:\n",
      "categoria\n",
      "Leve        135\n",
      "Moderado     29\n",
      "Fuerte        2\n"
     ]
    }
   ],
   "source": [
    "conteos_categoria = df['categoria'].value_counts().reindex(labels, fill_value=0)\n",
    "print(\"Conteos totales por categoría:\")\n",
    "print(conteos_categoria.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c07430",
   "metadata": {},
   "source": [
    "### Magnitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fd4fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteos por rango de profundidad:\n",
      "rango_profundidad\n",
      "Leve        0\n",
      "Moderado    0\n",
      "Fuerte      0\n"
     ]
    }
   ],
   "source": [
    "conteos_profundidad = df['rango_profundidad'].value_counts().reindex(labels, fill_value=0)\n",
    "print(\"Conteos por rango de profundidad:\")\n",
    "print(conteos_profundidad.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90248a3",
   "metadata": {},
   "source": [
    "### Categoria por región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2251cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sismos por región y categoría:\n",
      "categoria                         Leve  Moderado  Fuerte  Total\n",
      "region                                                         \n",
      "Antofagasta                         51         9       0     60\n",
      "Coquimbo                            26         8       1     35\n",
      "Tarapacá                            23         6       1     30\n",
      "Atacama                             13         3       0     16\n",
      "Libertador B. O'Higgins              6         0       0      6\n",
      "Valparaíso                           4         1       0      5\n",
      "Arica y Parinacota                   3         0       0      3\n",
      "Ñuble                                3         0       0      3\n",
      "Los Lagos                            1         1       0      2\n",
      "Región Metropolitana de Santiago     1         1       0      2\n",
      "Maule                                2         0       0      2\n",
      "Biobío                               1         0       0      1\n",
      "La Araucanía                         1         0       0      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcx\\AppData\\Local\\Temp\\ipykernel_244\\1522825040.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  conteos = df.groupby(['region', 'categoria']).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "conteos = df.groupby(['region', 'categoria']).size().unstack(fill_value=0)\n",
    "conteos['Total'] = conteos.sum(axis=1)\n",
    "conteos = conteos.sort_values('Total', ascending=False)\n",
    "print(\"Sismos por región y categoría:\")\n",
    "print(conteos.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70283fd7",
   "metadata": {},
   "source": [
    "### Manitud por región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ef78c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen estadístico de magnitud por región (top por cantidad):\n",
      "                                  count      mean       std  min  max\n",
      "region                                                               \n",
      "Antofagasta                          60  3.053333  0.491786  2.3  4.8\n",
      "Coquimbo                             35  3.257143  0.714672  2.5  5.5\n",
      "Tarapacá                             30  3.070000  0.695875  2.5  5.6\n",
      "Atacama                              16  2.956250  0.572676  2.5  4.2\n",
      "Libertador B. O'Higgins               6  3.050000  0.403733  2.5  3.5\n",
      "Valparaíso                            5  3.040000  0.378153  2.6  3.6\n",
      "Arica y Parinacota                    3  2.766667  0.230940  2.5  2.9\n",
      "Ñuble                                 3  3.000000  0.360555  2.6  3.3\n",
      "Los Lagos                             2  3.400000  0.282843  3.2  3.6\n",
      "Región Metropolitana de Santiago      2  3.500000  0.282843  3.3  3.7\n",
      "Maule                                 2  2.600000  0.000000  2.6  2.6\n",
      "Biobío                                1  3.300000       NaN  3.3  3.3\n",
      "La Araucanía                          1  2.600000       NaN  2.6  2.6\n"
     ]
    }
   ],
   "source": [
    "resumen = df.groupby('region')['magnitud'].agg(['count','mean','std','min','max']).sort_values('count', ascending=False)\n",
    "print(\"Resumen estadístico de magnitud por región (top por cantidad):\")\n",
    "print(resumen.head(20).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
